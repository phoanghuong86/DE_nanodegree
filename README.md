
 
 <br />
 <h1 align="center">Data Engineering Nanodegree</h1>
 <p align="center">  Udacity Nanodegree
  
## About The Nanodegree
 

This degree is about the path to be a data engineers which is defined by Coursera as "Data engineering is the practice designing and building systems for collecting, storing, and analyzing data at scale. It is a broad field with applications in just about every industry. Organizations have the ability to collect massive amounts of data, and they need the right people and technology to ensure the data is in a highly usable state by the time it reaches the data scientists and analysts." 
And as a data engineer, your daily job will be "Data engineers work in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret. Their ultimate goal is to make data accessible so that organizations can use it to evaluate and optimize their performance."

## **Program Details**

During this program,  we will have a tour around four courses and five projects. Via four projects,  we will play the role as a data engineer at a music streaming company. We will work with the **same dataset** in each project, but with increasing the requirements and assumption. The course's breakdown:

#### **Course 1 – Data Modeling**
With this course, we will learn to create data modeling with both relational and non-relational (NoSQL) system. 
We will have two projects to work with SQL (Postgres) and NoSQL (Cassandra) to build data model with user data from music streaming company.

#### **Course 2 – Cloud Data Warehouses**

We will learn to create cloud-based data warehouses. 
The project requirement is that we will build an ELT pipeline that extracts data from Amazon S3 and  load it to Amazon Redshift, and transforms it into dimensional tables.

#### **Course 3 – Data Lakes with Apache Spark**

We will learn more about the big data ecosystem, how to work with massive datasets and how to store big data.
The project needs to build an ETL pipeline for a data lake using Apache Spark and AWS S3 service.

#### **Course 4 – Data Pipelines with Apache Airflow**

This course will use Apache Airflow to schedule, automate, and monitor data pipelines.
The project will cover all works from previous project with applying Airflow to demo how to take advances of Apache

#### **Capstone Project**

The Capstone project, we use Twitter data, World happiness and earth surface temperature data to explore whether there is any correlation between the above. 
The Twitter data is dynamic and the other two dataset are static in nature. The idea of this project is to extract Twitter data, analyze  its sentiment and use the resulting data to gain insights with the other datasets.

## Contact

Huong Pho - phoanghuong86@gmail.com

Project Link: https://github.com/phoanghuong86/DE_nanodegree


